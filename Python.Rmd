---
title: "Python"
author: "Olusoji"
date: "2023-11-01"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(shiny)
tags$strong("This is some text")
```


```{r}
library(shiny)

ui <- fluidPage(
  tags$h1("This is some text")
  tags$img(scr = "https://upload.wikimedia.org/wikipedia/commons/c/c1/Ohio_State_Buckeyes_logo.svg" 
     height="100" 
     width="100"),
)

server <- function(input, output, session) {
  
}

shinyApp(ui, server)
```


create a new branch
move to it
edit read.me
commit and push that branch
merge on git hub
pull into main from github

git checkout -b <branchname> --- create branch

git checkout branchname --- move branch


```{r}
library(reticulate)
repl_python()
```

list out all the environment available 

```{r}
reticulate::conda_list()
```

You can create a new conda environment with
```{r}
reticulate::conda_create(envname = "temp")
```


You can install packages into environment with 

```{r}
reticulate::conda_install(envname = "base", packages = c("numpy", "pandas", "seaborn"))
```

You can choose what environment to use by
```{r}
reticulate::use_condaenv("base")
```


```{r}
data("mtcars")
```

Use r to access all r file
```{python}
x = 1
r.mtcars
```


numby
pandas
seaborn


In python use import to load data
```{python}
import numpy as np
```

In python, use =, not <- 
```{python}
x = 10
x + 2
X - 2
X / 2
x * 2
X**2 # x squared
x % 2 ## remanider after dividing by 2

# coommenstare the same
```


List in python are created using []

```{python}
y = [2, "hello world", True]
y
```

you can creatae numpy arrays as the equivalent of vectors
```{python}
z = np.array([1, 2, 3, 4])
z + 2
z / 2
z * 2
np.log(z)
```
```{python}
 True and True
 True and False
 False and True
 False and False
 True or True
 True or False
 False or True
 False or False
```


you can subset numpy arrays also with []
```{python}
z[1]
z[0] ## this is the first element
z[[0, 2, 3]]
```
You slice with :

```{python}
z[:3] ## give the first three element
Z[2: ] ## gives the third thorough last elements
z[1:3] ## will give te second and third element
```

Vectorized operation are possible in numpy

```{python}
y = np.array([5, 6, 7, 8])
x + y
```



numpy has useful functions inside

```{python}
np.sum(x)
np.mean(x)
np.log(x)
np.max(x)
```


```{python}
y.sum() ## The matod sum() attached to y
np.sum(y) ## The np.sum() function applied to y
```
```{python}
y.mean()
```



logical operations are similar in python

```{python}
y > 6
False ## not FALSE
y != 5
```

```{python}
2 > 4
 np.array([1, 2]) > np.array([0, 4])
 np.array([1, 2]) > 0
```
```{python}
x = np.array([1, 2])
 x > 0
```
```{python}
 x = np.array([6, 7, 8, 9])
 x[0]
 x[1, 2]
 x[[1, 2]]
 x[0:2]
```


You can use logical operator for subsetting

```{python}
y[y > 5] ## Returns a np array with elements greater than 5
```

Use & and | for and or in np array

```{python}
y[(y > 5) & (y < 8)]
```

But if you are working with bolians (logicals of length 1) use 'and' or 'or'

```{python}
True and True
True and False
True or False
```


Excercise

```{python}
y=(1,7,1,2,8,2)
x=(4,6,2,7,8,2)
```


```{python}
y = np.array([1,7,1,2,8,2])
x = np.array([4,6,2,7,8,2])
x * y
np.sum(x*y)
```

2. 
```{python}
x = np.array([4, 7, 8, 1, 2])
x[[1, 4]]
x[[False, True,  False, False, True]]
```

## Pandas
Use pd to import data

```{r}
library(tidyverse)
```

```{python}
import pandas as pd
```


```{r}
estate <- read_csv("estate.csv")
```

```{python}
estate = pd.read_csv("estate.csv")
estate
```

```{r}
glimpse(estate)
```

```{python}
estate.head()
estate.info()
```


You can extract a column from the data frame using like you would in R

```{python}
estate.Price
np.mean(estate.Price)
```

You can use np function on the resulting "Panda series" object

Filtering row
We want houses wiht a price over 300000 and an area under 2500 use query() to subset rows in pandas
```{python}
estate.query("(Price > 300000) & (Area < 2500)")
```





Another way using bracket for subsetting
```{python}
estate[(estate.Price > 300000) & (estate.Area < 2500)]
```


You can get certain rows based on row numbers using iloc

```{python}
estate.iloc[[0, 4, 7]] ## first fifth and eighth rows
```
Sort by arranging 
```{python}
estate.sort_values(by="Area", ascending=True)
```


Excercise 2

```{python}
df1 = estate.query("(Quality == 'Medium') & (Pool == 1)")
df1.sort_values(by="Price", ascending = True)
```
In r program

```{r}
estate |>
  filter(Quality == "Medium"
         Pool == 1) |>
  arrange(Price)
```

Method chainig: call a method after calling a method after calling a method

```{python}
(
   estate.query("(Quality == 'Medium') & (Pool == 1)")
   .sort_values(by = "Price", ascending = True)
)
```


Select column

We want to select price and Area

```{r}
select(estate, Price, Area)
```

USe filter() to select columns in Python 

```{pythin}
estate.filter(["Price", "Area"])
```

Negative subsetting is not allowed in Python. Use drop() with axis = 1
```{python}
estate.drop(["Price", "Area"], axis = 1) # 0 = index (for rows and 1 = column)
```

Dictionary: BAse python object created with {} that have key-vale pairs

```{python}
x = {"Bob:1", "Mary:2", "John:3"}
x
```

You can use dcitionary object to rename varables in python with rename() method

```{python}
estate.rename({'Price': 'Newname', 'Area': 'Anothernewname'}, axis = 'columns')
```

In r
```{r}
estate |>
  rename(Newname = Price)
```



Mutate in python (Creating a new variable)

```{python}
(
  estate.eval("age = 2013 - Year")
  .filter(["age"])
)
```



## 11/8/2023

```{r}
library(reticulate)
```

```{r}
data <- read_csv("estate.csv")
```
```{python}
estate = pd.read_csv("estate.csv")
estate
```


```{python}
estate.info()
```
Group summaries


```{python}
(
estate.filter(["Price", "Area", "Bed", "Bath"])
  .groupby(["Bed", "Bath"])
  .agg(np.mean)
)
```


```{python}
monkeymem  = pd.read_csv(" https://data-science-master.github.io/lectures/data/tidy_exercise/monkeymem.csv")
```

```{python}
monkeymem.info()
```

```{python}
data("table2")
```


```{python}
table2 = r.table2
```

```{python}
(
table2.pivot_table(index=['country', 'year'], columns='type', values='count')
  .reset_index()
)
```

Excercise 

```{python}
flowers1 = pd.read_csv("https://data-science-master.github.io/lectures/data/tidy_exercise/flowers1.csv", sep=";", decimal=";")

(
  flowers.pivot_tabel(index
  
)
)
```

## Separating
```{python}
table3 = r.table3
```



```{python}
table3[['cases', 'population']] = table3.rate.str.split(pat = '/', expand = True)
table3.drop('rate', axis=1)
```
```{r}
separate(table3, col = "rate", sep = "/", into = c("cases", "population"))
separate_wider_delim(table3, rate, delim = "/", names = c("cases", "pop"))

```

```{python}
flowers2  = pd.read_csv(" https://data-science-master.github.io/lectures/data/tidy_exercise/flowers2.csv")

flowers2[['Flowers', 'Intensity']] = flowers2['Flowers/intensity'].str.split(pat = '/', expand = True)

flowers2 = flowers2.drop('Flowers/Intensity', axis=1)
```



Uniting

```{python}
table5 = r.table5
```


```{python}
(
table5.assign(year = table5.century.str.cat(table5.year))
  .drop('century', axis = 1)
)
```

## Joining

```{python}
xdf = pd.DataFrame({"mykey": np.array([1, 2, 3]), 
                    "x": np.array(["x1", "x2", "x3"])})
ydf = pd.DataFrame({"mykey": np.array([1, 2, 4]), 
                    "y": np.array(["y1", "y2", "y3"])})
xdf
ydf
```

Binding rows

```{python}
pd.concat([xdf, ydf])
```

Merge

```{python}
pd.merge(left=xdf, right=ydf, how="inner", on="mykey")
pd.merge(left=xdf, right=ydf, how="left", on="mykey")
pd.merge(left=xdf, right=ydf, how="right", on="mykey")
```


Plot in python

```{r}
library(ggplot2)
data("mpg")
```


```{python}
import matplotlib.pyplot as plt
import seaborn as sns
mpg = r.mpg
```

```{python}
sns.histplot(x='hwy', data=mpg)
plt.show()
```


One Categorical Variable: Barplot

```{python}
sns.countplot(x='class', data=mpg)
plt.show()
```


One Quantitative Variable, One Categorical Variable: Boxplot

```{python}
sns.boxplot(x='class', y='hwy', data=mpg)
plt.show()
```


Two Quantitative Variables: Scatterplot

```{python}
sns.scatterplot(x='displ', y='hwy', data=mpg)
plt.show()

```


Lines/Smoothers for regression

```{python}
sns.regplot(x='displ', y='hwy', data=mpg)
plt.show()
```

## Loess smoother with confidence interval removed.

```{python}
sns.regplot(x='displ', y='hwy', data=mpg, lowess=True, ci='None')
plt.show()
```


Two Categorical Variables: Mosaic Plot

```{python}
pd.crosstab(mpg['class'], mpg['drv'], normalize='all')
pd.crosstab(mpg['class'], mpg['drv'], normalize='index')
pd.crosstab(mpg['class'], mpg['drv'], normalize='columns')

```
Facets
Use sns.FacetGrid() followed by the map_dataframe() method to plot facets. You pass arguments to the plot (sns.histplot() or sns.scatterplot() etc) inside the map function.

```{python}
g = sns.FacetGrid(data=mpg, row='drv', col='class')
g = g.map_dataframe(sns.histplot, x = 'hwy', kde=False)
plt.show()
```


---
title: "HW 09: Python"
author: "YOUR NAME HERE"
date: "`r Sys.Date()`"
output: html_document
urlcolor: "blue"
params:
  solutions: TRUE
---

Â© 2023 David Gerard, not to be posted online, or uploaded to an AI.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo       = params$solutions, 
                      eval       = params$solutions,
                      fig.align  = "center",
                      fig.height = 3, 
                      fig.width  = 5)
```

# Instructions

- Write your solutions in this starter file. You should modify the 
  "author" field in the YAML header.
- Only commit R Markdown and HTML files (no PDF files). Make sure
  you have knitted to HTML for your final submission.
- **Make sure to commit each time you answer a question.**
- Only include the necessary code, not any extraneous code, to answer the 
  questions.
- Use only Python code (no R code). 
- Use only Python functions from numpy, pandas, and seaborn (and functions that come with base Python).
- Do not change the path of any files.
- Learning objectives:
    - Numpy, Pandas, Seaborn

# World Bank Data

The World Bank is an international organization that
provides loans to countries with the goal of reducing poverty. The 
data frames in the dt folder were all taken from the public data 
repositories of the World Bank.

- country.csv: 
  Contains information on the countries in the data set. The
  variables are:
    - `Country_Code`: A three-letter code for the country. Note that not all
      rows are countries; some are regions.
    - `Region`: The region of the country.
    - `IncomeGroup`: Either `"High income"`, `"Upper middle income"`, 
      `"Lower middle income"`, or `"Low income"`.
    - `TableName`: The full name of the country.
- fertility.csv: 
  Contains the fertility rate information for each country
  for each year. For the variables `1960` to `2017`, the values in the cells
  represent the fertility rate in total births per woman for the that year. 
  Total fertility rate represents the number of children 
  that would be born to a woman if she were to live to the end of her 
  childbearing years and bear children in accordance with age-specific 
  fertility rates of the specified year.
- life_exp.csv: 
  Contains the life expectancy information for each country 
  for each year. For the variables `1960` to `2017`, the values in the cells
  represent life expectancy at birth in years for the given year. 
  Life expectancy at birth indicates the number of years a newborn 
  infant would live if prevailing patterns of mortality at the time of its
  birth were to stay the same throughout its life.
- population.csv: 
  Contains the population information for each country. For
  the variables `1960` to `2017`, the values in the cells represent the total
  population in number of people for the given year. 
  Total population is based on the de facto definition of
  population, which counts all residents regardless of legal status or 
  citizenship. The values shown are midyear estimates.
  
1. (1 pt) Use relative paths to load these data frames into Python.

```{python}
import pandas as pd
```

```{python}
country = pd.read_csv("country.csv")
fertility = pd.read_csv("fertility.csv")
life_exp= pd.read_csv("life_exp.csv")
population = pd.read_csv("population.csv")
```


    
2. (2 pts) These data are messy. The observational units in `fert`, `life`, and `pop`
   are locations in space-time (e.g. Aruba in 2017). Recall that tidy data
   should have one observational unit per row. Make these data tidy now.
   
```{python}
fertility_df = pd.melt(fertility, id_vars=['Country Name', 'Country Code'], var_name='year', value_name='fert_rate')


life_expectancy_df = pd.melt(life_exp, id_vars=['Country Name', 'Country Code'], var_name='year', value_name='life_exp')

population_df = pd.melt(population, id_vars=['Country Name', 'Country Code'], var_name='year', value_name='population')
```
   
    
3. (2 pts) Combine these data frames so that we have the fertility rate, population,
   life expectancy, and the region for each country in each year in a single
   data frame. The resulting data frame should look like this
   
```{python}
wb_df = pd.merge(country, fertility_df, left_on=['Country Code'], right_on=['Country Code'], how='left')

wb_df = pd.merge(wb_df, life_expectancy_df, left_on=['Country Code', 'year'], right_on=['Country Code', 'year'], how='left')

wb_df = pd.merge(wb_df, population_df, left_on=['Country Code', 'year'], right_on=['Country Code', 'year'], how='left')

wb_df = wb_df[['Country Name_x', 'Country Code', 'year', 'fert_rate', 'Country Name_y', 'life_exp', 'population', 'Region']]

wb_df.columns = ['Country Name', 'Country Code', 'Year', 'Fertility Rate', 'Country Name_y', 'Life Expectancy', 'Population', 'Region']

wb_df.head()
wb_df.info()

```


   
    
4. (2 pts) Make a scatterplot of fertility rate vs life expectancy, color-coding by region. Do this for the years 1960, 1970, 1980, 1990, 2000, and 2010. Facet by these years. Make your plot aesthetically pleasing.  Your final plot should look like this:

```{python}
import seaborn as sns
import matplotlib.pyplot as plt

# Assuming 'df' is a pandas DataFrame with 'fertility_rate', 'life_expectancy', 'region', and 'year' columns

# FacetGrid to create a grid of plots
g = sns.FacetGrid(df, col="year", hue="region", col_wrap=3, sharey=False, sharex=False)

# Adding the scatter plots to each subplot in the grid
g = g.map(plt.scatter, "life_expectancy", "fertility_rate")

# Adding a legend
g.add_legend()

# Adjusting the aesthetics, if necessary
g.set_titles("year = {col_name}")
g.set_axis_labels("Life Expectancy", "Fertility Rate")

# Showing the plot
plt.show()


```

    
5. (2 pts) Calculate the total population for each region for each year. Exclude 2018. 
   Make a line plot of year versus total population, color-coding by region.
   Your final plot should look like this:
    
6. (2 pts) Make a bar plot of population vs region for the year 2017. Your final  plot should look like this:

```{r}

```
























  